---
author-meta:
- Trang T. Le
- Daniel S. Himmelstein
- Ariel A. Hippen Anderson
- Matthew R. Gazzara
- Casey S. Greene
bibliography:
- content/manual-references.json
date-meta: '2020-04-01'
header-includes: '<!--

  Manubot generated metadata rendered from header-includes-template.html.

  Suggest improvements at https://github.com/manubot/manubot/blob/master/manubot/process/header-includes-template.html

  -->

  <meta name="dc.format" content="text/html" />

  <meta name="dc.title" content="Analysis of ISCB honorees and keynotes reveals disparities" />

  <meta name="citation_title" content="Analysis of ISCB honorees and keynotes reveals disparities" />

  <meta property="og:title" content="Analysis of ISCB honorees and keynotes reveals disparities" />

  <meta property="twitter:title" content="Analysis of ISCB honorees and keynotes reveals disparities" />

  <meta name="dc.date" content="2020-04-01" />

  <meta name="citation_publication_date" content="2020-04-01" />

  <meta name="dc.language" content="en-US" />

  <meta name="citation_language" content="en-US" />

  <meta name="dc.relation.ispartof" content="Manubot" />

  <meta name="dc.publisher" content="Manubot" />

  <meta name="citation_journal_title" content="Manubot" />

  <meta name="citation_technical_report_institution" content="Manubot" />

  <meta name="citation_author" content="Trang T. Le" />

  <meta name="citation_author_institution" content="Department of Biostatistics, Epidemiology and Informatics, Institute for Biomedical Informatics, University of Pennsylvania" />

  <meta name="citation_author_orcid" content="0000-0003-3737-6565" />

  <meta name="twitter:creator" content="@trang1618" />

  <meta name="citation_author" content="Daniel S. Himmelstein" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania" />

  <meta name="citation_author_orcid" content="0000-0002-3012-7446" />

  <meta name="twitter:creator" content="@dhimmel" />

  <meta name="citation_author" content="Ariel A. Hippen Anderson" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania" />

  <meta name="citation_author_orcid" content="0000-0001-9336-6543" />

  <meta name="twitter:creator" content="@AHippenAnderson" />

  <meta name="citation_author" content="Matthew R. Gazzara" />

  <meta name="citation_author_institution" content="Department of Genetics, Perelman School of Medicine, University of Pennsylvania" />

  <meta name="citation_author_orcid" content="0000-0001-7710-4551" />

  <meta name="twitter:creator" content="@MR_Gazzara" />

  <meta name="citation_author" content="Casey S. Greene" />

  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania" />

  <meta name="citation_author_institution" content="Childhood Cancer Data Lab, Alex&#39;s Lemonade Stand Foundation" />

  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />

  <meta name="twitter:creator" content="@greenescientist" />

  <link rel="canonical" href="https://greenelab.github.io/iscb-diversity-manuscript/" />

  <meta property="og:url" content="https://greenelab.github.io/iscb-diversity-manuscript/" />

  <meta property="twitter:url" content="https://greenelab.github.io/iscb-diversity-manuscript/" />

  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/iscb-diversity-manuscript/" />

  <meta name="citation_pdf_url" content="https://greenelab.github.io/iscb-diversity-manuscript/manuscript.pdf" />

  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/iscb-diversity-manuscript/manuscript.pdf" />

  <link rel="alternate" type="text/html" href="https://greenelab.github.io/iscb-diversity-manuscript/v/484fe91721c607da6e09b3394e6b85256b5456c5/" />

  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/iscb-diversity-manuscript/v/484fe91721c607da6e09b3394e6b85256b5456c5/" />

  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/iscb-diversity-manuscript/v/484fe91721c607da6e09b3394e6b85256b5456c5/manuscript.pdf" />

  <meta property="og:type" content="article" />

  <meta property="twitter:card" content="summary_large_image" />

  <meta property="og:image" content="https://github.com/greenelab/iscb-diversity-manuscript/raw/484fe91721c607da6e09b3394e6b85256b5456c5/build/assets/thumbnail.png" />

  <meta property="twitter:image" content="https://github.com/greenelab/iscb-diversity-manuscript/raw/484fe91721c607da6e09b3394e6b85256b5456c5/build/assets/thumbnail.png" />

  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />

  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />

  <meta name="theme-color" content="#ad1457" />

  <!-- end Manubot generated metadata -->'
keywords:
- computational biology
- iscb
- disparities
lang: en-US
manubot-clear-requests-cache: false
manubot-fail-on-errors: true
manubot-output-bibliography: output/references.json
manubot-output-citekeys: output/citations.tsv
manubot-requests-cache-path: ci/cache/requests-cache
title: Analysis of ISCB honorees and keynotes reveals disparities
...




This version of the manuscript [contains changes](https://github.com/greenelab/iscb-diversity-manuscript/compare/v1.0...484fe91721c607da6e09b3394e6b85256b5456c5) subsequent to the [version 1.0 release](https://github.com/greenelab/iscb-diversity-manuscript/releases/tag/v1.0).


<small><em>
This manuscript
([permalink](https://greenelab.github.io/iscb-diversity-manuscript/v/484fe91721c607da6e09b3394e6b85256b5456c5/))
was automatically generated
from [greenelab/iscb-diversity-manuscript@484fe91](https://github.com/greenelab/iscb-diversity-manuscript/tree/484fe91721c607da6e09b3394e6b85256b5456c5)
on April 1, 2020.
</em></small>

<!-- include the Font Awesome library, per: https://fontawesome.com/start -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css">

## Authors



+ **Trang T. Le**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0003-3737-6565](https://orcid.org/0000-0003-3737-6565)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [trang1618](https://github.com/trang1618)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [trang1618](https://twitter.com/trang1618)<br>
  <small>
     Department of Biostatistics, Epidemiology and Informatics, Institute for Biomedical Informatics, University of Pennsylvania
  </small>

+ **Daniel S. Himmelstein**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0002-3012-7446](https://orcid.org/0000-0002-3012-7446)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [dhimmel](https://github.com/dhimmel)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [dhimmel](https://twitter.com/dhimmel)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania
  </small>

+ **Ariel A. Hippen Anderson**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-9336-6543](https://orcid.org/0000-0001-9336-6543)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [arielah](https://github.com/arielah)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [AHippenAnderson](https://twitter.com/AHippenAnderson)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania
  </small>

+ **Matthew R. Gazzara**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-7710-4551](https://orcid.org/0000-0001-7710-4551)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [mrgazzara](https://github.com/mrgazzara)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [MR_Gazzara](https://twitter.com/MR_Gazzara)<br>
  <small>
     Department of Genetics, Perelman School of Medicine, University of Pennsylvania
  </small>

+ **Casey S. Greene**<br>
    ![ORCID icon](images/orcid.svg){.inline_icon}
    [0000-0001-8713-9213](https://orcid.org/0000-0001-8713-9213)
    · ![GitHub icon](images/github.svg){.inline_icon}
    [cgreene](https://github.com/cgreene)
    · ![Twitter icon](images/twitter.svg){.inline_icon}
    [greenescientist](https://twitter.com/greenescientist)<br>
  <small>
     Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex's Lemonade Stand Foundation
  </small>



## Abstract

Professional societies and the conferences that they manage provide an important venue for the dissemination of scientific knowledge.
Being invited to deliver a keynote at an international society meeting or named a fellow of such a society is a major recognition.
We sought to understand the extent to which such recognitions reflected the composition of their corresponding field.
We collected keynote speaker invitations for the international meetings held by the International Society for Computational Biology as well as the names of Fellows, an honorary group within the society.
We compared these honorees with last and corresponding author contributions in field-specific journals.
We used multiple methods to estimate the race, ethnicity, gender, and name groupings of authors and the recipients of these honors.
To address weaknesses in existing approaches, we built a new dataset of more than 700,000 people with name-nationality pairs from Wikipedia and trained long short-term memory neural networks to make predictions.
Although we observe similar gender distributions between the group of honorees and authors, the proportion of female scientists in the field has not yet reached parity.
Through each method, we find that white scientists are overrepresented among speakers and honorees, while scientists of color are underrepresented.


## Introduction

Scientists' roles in society include identifying important topics of study, undertaking an investigation of those topics, and disseminating their findings broadly.
The scientific enterprise is largely self-governing: scientists act as peer reviewers on papers and grants, comprise hiring committees in academia, make tenure decisions, and select which applicants will be admitted to doctoral programs.
A lack of diversity in science could lead to pernicious biases that hamper the extent to which scientific findings are relevant to minority communities.
For example, a recent analysis found that minority scientists tend to apply for awards on topics with lower success rates [@doi:10.1126/sciadv.aaw7238].
This finding might be the result of minority scientists selecting topics in more poorly funded areas.
Alternatively, reviewing scientists may not recognize the scientific importance of these topics, which may be of particular interest to minority scientists.
One way to address this issue is to directly examine peer recognition in different scientific fields.

Gender bias among conference speakers has been recognized as an area that can be improved with targeted interventions [@doi:10.1371/journal.pcbi.1003903; @doi:10.1126/science.caredit.aaw9742; @doi:10.1038/ni.3707; @arxiv:1502.06326].
Having more female organizers on conference committees is associated with having more female speakers [@doi:10.1128/mBio.00846-13].
At medical conferences in the US and Canada, the proportion of female speakers is increasing at a modest rate [@doi:10.1001/jamanetworkopen.2019.2103].
Gender bias appears to also influence funding decisions: an examination of scoring of proposals in Canada found that reviewers asked to assess the science produced a smaller gender gap in scoring than reviewers asked to assess the applicant [@doi:10/djc5].
Challenges extend beyond gender: an analysis of awards at the NIH found that proposals by Asian, black or African-American applicants were less likely to be funded than those by white applicants [@doi:10.1126/science.1196783].
There are also potential interaction effects between gender and race or ethnicity that may particularly affect women of color's efforts to gain NIH funding [@doi:10.1097/ACM.0000000000001278].

We sought to understand the extent to which honors and high-profile speaking invitations were distributed equitably among gender, race/ethnicity, and name origin groups by an international society and its associated meetings.
As computational biologists, we focused on the [International Society for Computational Biology](https://www.iscb.org/) (ISCB), its honorary Fellows as well as its affiliated international meetings that aim to have a global reach: [Intelligent Systems for Molecular Biology](https://en.wikipedia.org/wiki/Intelligent_Systems_for_Molecular_Biology) (ISMB) and [Research in Computational Molecular Biology](https://en.wikipedia.org/wiki/Research_in_Computational_Molecular_Biology) (RECOMB).

We used multiple methods to predict the gender, race/ethnicity, and name origins of honorees.
Existing methods were relatively US-centric because most of the data was derived in whole or in part from the US Census.
We scraped more than 700,000 entries from English-language Wikipedia that contained nationality information to complement these existing methods and built multiple machine learning classifiers to predict name origin.
We also examined the last and corresponding authors for publications in ISCB partner journals to establish a field-specific baseline using the same metrics.
The results were consistent across all approaches: we found a dearth of non-white speakers and honorees.
The lack of Asian scientists among keynote speakers and Fellows was particularly pronounced when compared against the field-specific background.


## Materials and Methods

### Honoree Curation

From [ISCB's webpage listing **ISCB Distinguished Fellows**](http://web.archive.org/web/20200116150052/https://www.iscb.org/iscb-fellows), we found recipients listed by their full names for the years 2009--2019.
We gleaned the full name of the Fellow as well as the year in which they received the honor.
We identified major ISCB-associated conferences as those designated flagship (ISMB) or those that had been held on many continents (RECOMB).
To identify **ISMB Keynote Speakers**, we examined the webpage for each ISMB meeting.
The invited speakers at ISMB before 2001 were listed in the Preface pages of each year's proceedings, which were archived in the [ISMB collection](https://aaai.org/Library/ISMB/ismb-library.php) of the AAAI digital library.
We found full names of all keynote speakers for the years 1993--2019.

For the RECOMB meeting, we found conference webpages with keynote speakers for 1999, 2000, 2001, 2004, 2007, 2008, and 2010--2019.
We were able to fill in the missing years using information from the RECOMB 2016 proceedings, which summarizes the first 20 years of the RECOMB conference [@doi:10.1007/978-3-319-31957-5].
This volume has two tables of keynote speakers from 1997--2006 (Table 14, page XXVII) and 2007--2016 (Table 4, page 8).
Using these tables to verify the conference speaker lists, we arrived at two special instances of inclusion/exclusion.
Although Jun Wang was not included in these tables, we were able to confirm that he was a keynote speaker in 2011 with the RECOMB 2011 proceedings [@doi:10.1007/978-3-642-20036-6], and thus we included this speaker in the dataset.
Marian Walhout was invited as a keynote speaker but had to [cancel](http://recomb2015.mimuw.edu.pl/node/18.html) the talk due to other obligations.
Because her name was neither mentioned in the 2015 proceedings [@doi:10.1007/978-3-319-16706-0] nor in the above-mentioned tables, we excluded this speaker from our dataset.

#### Name processing

When extracting honoree names, we began with the full name as provided on the site.
Because our prediction methods required separated first and last names, we chose the first non-initial name as the first name and the final name as the last name.
We did not consider a hyphen to be a name separator:
for hyphenated names, all components were included.
For metadata from PubMed and PMC where first (fore) and last names are coded separately, we applied the same cleaning steps.
We created [functions to simplify names](https://git.dhimmel.com/pubmedpy/names.html) in the pubmedpy Python package to support standardized fore and last name processing.

### Corresponding author extraction

We assumed that, in the list of authors for a specific paper, corresponding authors (often research advisors) would be most likely to be invited for keynotes or to be honored as Fellows.
Therefore, we collected corresponding author names to assess the composition of the field, weighted by the number of corresponding authors per publication.

We evaluated two resources for extracting corresponding authors from papers: [PubMed](https://pubmed.ncbi.nlm.nih.gov/) and [PubMed Central](https://www.ncbi.nlm.nih.gov/pmc/) (PMC).
Both resources are provided by the US National Library of Medicine and index scholarly articles.
PubMed contains a record for every article published in journals it indexes (30 million records total circa 2020) and provides abstracts but not fulltext.
PMC, which provides fulltext access, does not contain every article from every journal (5.9 million records total circa 2020).
In general, open access journals will deposit their entire catalog to PMC (e.g., _BMC Bioinformatics_ & _PLOS Computational Biology_), while toll access journals (e.g., _Bioinformatics_) will only deposit articles when funders require it.
Since PMC requires publishers to submit fulltext articles in a structured XML format, the machine-readability and breadth of metadata in PMC is often superior to PubMed.

Of PMC's 5.9 million fulltext articles, only 2.7 million are part of the "[Open Access Subset](https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/)" which allows for downloading the structured fulltext as opposed to just viewing the article online.
However, authorship information does not require full text records.
We were able to download structured frontmatter (rather than fulltext) records from PMC's [OAI-PMH service](https://www.ncbi.nlm.nih.gov/pmc/tools/oai/), so we were not limited to just the Open Access Subset.
For PubMed, we used the E-Utilities APIs.
For PubMed records, we were able to extract author first and last names and their order within a record.
For PMC, we were able to extract these fields as well as whether each author was a corresponding author.
To automate and generalize these tasks, we created the [pubmedpy](https://github.com/dhimmel/pubmedpy) Python package.

We selected three journals to represent the field of bioinformatics and computational biology, including two ISCB Partner Journals (_PLOS Computational Biology_ and _Bioinformatics_) and one field-specific journal that is not a partner (_BMC Bioinformatics_).
From PubMed, we compiled a catalog of 29,755 journal articles published from when each journal was established through 2019.
We were able to retrieve authorship information for all but 6 of these articles using PubMed or PubMed Central.

To determine corresponding authors for an article, we relied on PMC data if available (20,696 articles) and otherwise fell back to PubMed data (9,053 articles).
Almost all articles without PMC data were from _Bioinformatics_ because it is a "selective deposit" rather than "full participation" journal in PMC.

We performed further analysis on PMC authors to learn more about corresponding author practices.
First, we developed and evaluated a method to infer a corresponding author when the coded corresponding status was not available.
For papers with multiple authors and at least one corresponding author, the first author was corresponding 43% of the time, whereas the last author was corresponding 62% of the time.
Therefore, we assumed the last author was corresponding when coded corresponding author status was not available (120 articles from PMC and all articles from PubMed).

Second, we investigated the number of corresponding authors for PMC articles.
81% of these articles had a single corresponding author.
1.7% had no corresponding authors.
Of these, many were editorials (e.g., [PMC1183510](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1183510/), the announcement of _PLOS Computational Biology_).
A very small number of papers had over 10 corresponding authors.
Some of these instances were true outliers, like [PMC5001208](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001208/) with 21 corresponding authors.
Others like [PMC3509495](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3509495/) were incorrect, due to upstream errors.
To not give undue influence to papers with multiple corresponding authors, subsequent analyses on corresponding authors are inversely weighted by the number of corresponding authors per paper.

### Countries of Affiliations

Publications often provide affiliation lists for authors, which generally associate authors with research organizations and their corresponding physical addresses.
We implemented affiliation extraction in the pubmedpy Python package for both PubMed and PMC XML records.
These methods extract a sequence of textual affiliations for each author.
While ideally each affiliation record would refer to one and only one research organization, sometimes journals deposit multiple affiliations in a single structured affiliation.
For example, we extracted the following composite affiliation for all authors of [PMC4147893](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147893/):

> 'Multimodal Computing and Interaction', Saarland University & Department for Computational Biology and Applied Computing, Max Planck Institute for Informatics, Saarbrücken, 66123 Saarland, Germany, Ray and Stephanie Lane Center for Computational Biology, Carnegie Mellon University, Pittsburgh, 15206 PA, USA, Department of Mathematics and Computer Science, Freie Universität Berlin, 14195 Berlin, Germany, Université Pierre et Marie Curie, UMR7238, CNRS-UPMC, Paris, France and CNRS, UMR7238, Laboratory of Computational and Quantitative Biology, Paris, France.

We designed a method for extracting countries from affiliations that accommodated multiple countries.
We relied on two Python utilities to extract countries from text: [geotext](https://github.com/elyase/geotext) and [`geopy.geocoders.Nominatim`](https://geopy.readthedocs.io/en/stable/#nominatim).
The first, geotext, used regular expressions to find mentions of places from the [GeoNames database](http://www.geonames.org/).
In the above text, geotext detected four mentions of places in Germany: Saarland, Saarbrücken, Saarland, Germany.
Anytime geotext identified 2 or more mentions of a country, we labeled the affiliation as including that country.

`geopy.geocoders.Nominatim` converts names / addresses to geographic coordinates using the OpenStreetMap's [Nomatim](https://nominatim.org/) service.
We split textual affiliations by punctuation and found the first segment, in reverse order, that returned any Nomatim search results.
For the above affiliation, the search order was "France", "Paris", "Laboratory of Computational and Quantitative Biology", etcetera.
Since searching "France" returns a match by Nomatim, the following queries would not be made.
When a match was found, we extracted the country containing the location.
This approach returns a single country for an affiliation when successful.
When labeling affiliations with countries, we only used these values when geotext did not return results or had ambiguity amongst countries without multiple matches.
For more details on this approach, consult the accompanying [notebook](https://github.com/greenelab/iscb-diversity/blob/5213ba3451520af3967f74d8f58553dade0a826c/07.affiliations-to-countries.ipynb) and [label dataset](https://github.com/greenelab/iscb-diversity/blob/5213ba3451520af3967f74d8f58553dade0a826c/data/affiliations/geocode.jsonl).

Our ability to assign countries to authors was largely driven by the availability of affiliations.
In our catalog of corresponding authors, 95.7% of authors from PubMed Central records were assigned at least one country.
The country-assignment-rate for corresponding authors from PubMed records was only 32.2%. 
This reflects the varying availability of affiliation metadata by journal.
Countries were assigned to all corresponding authors for 99.9% of articles in _BMC Bioinformatics_ 98.7% in _PLOS Computational Biology_, and 49.6% in _Bioinformatics_.
Country assignment for corresponding authors in _Bioinformatics_ were unavailable for over half of all articles annually from 1998--2013.
_Bioinformatics_ affiliation metadata improved starting in 2014, and the country-assignment-rate has hovered around ~95% for the last few years (see [notebook](https://github.com/greenelab/iscb-diversity/blob/a7fcc7c229672b56626f0dc68d04064079ff3a49/08.corresponding-authors.ipynb)).

For ISCB honorees, during the curation process, if an honoree was listed with their affiliation at the time, we recorded this affiliation for analysis.
For ISCB Fellows, we used the affiliation listed on the ISCB page.
Because we could not find affiliations for the 1997 and 1998 RECOMB keynote speakers' listed for these years, they were left blank.
If an author or speaker had more than one affiliation, each was inversely weighted by the number of affiliations that individual had.

### Estimation of Gender

We predicted the gender of honorees and authors using the <https://genderize.io> API, which was trained on over 100 million name-gender pairings collected from the web and is one of the three widely-used gender inference services that provide gender classifications with over 98% accuracy [@doi:10.7717/peerj-cs.156].
We used author and honoree first names to retrieve predictions from genderize.io.
The predictions represent the probability of an honoree or author being male or female.
We used the estimated probabilities and did not convert to a hard group assignment.
For example, a query to <https://genderize.io> on January 26, 2020 for "Casey" returns a probability of male of 0.74 and a probability of female of 0.26, which we would add for an author with this first name.
Because of the limitations of considering gender as a binary trait and inferring it from first names, we only consider predictions in aggregate and not as individual values for specific scientists.

Of 412 ISCB honorees, genderize.io fails to provide gender predictions for three names.
Of 34,005 corresponding authors, 45 were missing a fore name altogether in the raw paper metadata and 1,466 had fore names consisting of only initials.
Of the remaining authors, genderize.io failed to predict gender for 1,578 of these fore names.
We note that approximately 52% of these NA predictions are hyphenated names, which is likely because they are more unique and thus are more difficult to find predictions for.
79% of these names were predicted to be of Asian origin by last name (see the race/ethnicity prediction model below).
This bias of NA predictions toward non-English names has been previously observed [@doi:10.32614/RJ-2016-002] and may have a minor influence on the final estimate of gender compositions.

### Estimation of Name Origin Groups

We developed a model to predict geographical origins of names.
The existing Python package ethnicolr [@arxiv:1805.02109] produces reasonable predictions, but its international representation in the data curated from Wikipedia in 2009 [@doi:10.1145/1557019.1557032] is still limited.
For instance, 76% of the names in ethnicolr's Wikipedia dataset are European in origin, and the dataset contains remarkably fewer Asian, African, and Middle Eastern names than wru.

To address these limitations in ethnicolr, we built a similar classifier, a Long Short-term Memory (LSTM) neural network, to infer the region of origin from patterns in the sequences of letters in full names.
We applied this model on an updated, approximately 4.5 times larger training dataset called Wiki2019 (described below).
We tested multiple character sequence lengths and, based on this comparison, selected tri-characters for the primary results described in this work.
We trained our prediction model on 80% of the Wiki2019 dataset and evaluated its performance using the remaining 20%.
This model, which we term Wiki2019-LSTM, is available in the online file [`LSTM.h5`](https://github.com/greenelab/wiki-nationality-estimate/blob/master/models/LSTM.h5).

To generate a training dataset for name origin prediction that reflects a modern naming landscape, we scraped the English Wikipedia's category of [Living People](https://en.wikipedia.org/wiki/Category:Living_people).
This category, which contained approximately 930,000 pages at the time of processing in November 2019, is regularly curated and allowed us to avoid pages related to non-persons.
For each Wikipedia page, we used two strategies to find a full birth name and location context for that person.
First, we used information from the personal details sidebar; the information in this sidebar varied widely but often contained a full name and a place of birth.
Second, in the body of the text of most English-language biographical Wikipedia pages, the first sentence usually begins with, for example, "John Edward Smith (born 1 January 1970) is an American novelist known for ..."
This structure comes from editor [guidance on biography articles](https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Biography#Context) and is designed to capture:

> ... the country of which the person is a citizen, national or permanent resident, or if the person is notable mainly for past events, the country where the person was a citizen, national or permanent resident when the person became notable.

We used regular expressions to parse out the person's name from this structure and checked that the expression after "is a" matched a list of nationalities.
We were able to define a name and nationality for 708,493 people by using the union of these strategies.
This process produced country labels that were more fine-grained than the broader patterns that we sought to examine among honorees and authors.
We initially grouped names by continent, but later decided to model our categorization after the hierarchical taxonomy used by [NamePrism](http://www.name-prism.com/about) [@doi:10.1145/3132847.3133008].
The NamePrism taxonomy was derived from name-country pairs by producing an embedding of names by Twitter contact patterns and then grouping countries using the similarity of names from those countries.
The countries associated with each grouping are shown in Fig {@fig:nameprism_countries}.
NamePrism excluded the US, Canada and Australia because these countries have been populated by a mix of immigrant groups [@doi:10.1145/3132847.3133008].

![NamePrism groups countries by name similarity. We used this grouping but renamed the groups to focus on the linguistic patterns based on name etymology identified by NamePrism.
](https://raw.githubusercontent.com/greenelab/iscb-diversity/286079d52a9ecc216f9e1364ec951e1c8dc09de8/figs/2020-01-31_groupings.png){#fig:nameprism_countries width="90%"}

In an earlier version of this manuscript, we also used category names derived from NamePrism, but a reader [pointed out](https://github.com/greenelab/iscb-diversity-manuscript/issues/27) the titles of the groupings were problematic;
therefore, in this version, we renamed these groupings to reflect that the NamePrism approach primarily identifies groups based on linguistic patterns from name etymology rather than religious or racial similarities.
We note that our mapping from nationality to name origins was not without error.
For example, a scientist of Israeli nationality may not bear a Hebrew name.
These mismatches were assessed via the heatmap of the model performance (Fig. {@fig:wiki2019_lstm}C) and complemented by the affiliation analysis below.
An alternative approach is to assign arbitrary names to these groups such as via letter coding (e.g., A, B, C, etc.), but we did not choose this strategy because ten arbitrary letters for ten groups can greatly reduce the paper's readibility.

### Affiliation Analysis

For each country, we computed the expected number of honorees by multiplying the proportion of authors whose affiliations were in that country with the total number of honorees.
We then performed an enrichment analysis to examine the difference in country affiliation proportions between ISCB honorees and field-specific corresponding authors.
We calculated each country's enrichment by dividing the observed proportion of honorees by the expected proportion of honorees.
The 95% confidence interval of the log~2~ enrichment was estimated using the Poisson model method [@isbn:978-0849394447, page 17-18].

### Estimation of Race and Ethnicity within the US

We predicted the race and ethnicity of US-affiliated honorees and authors using the R package wru.
wru implements methods described in Imai and Khanna [@doi:10.1093/pan/mpw001] to predict race and ethnicity using surname and location information.
The underlying data used for prediction are derived from the US Census, in which an individual's race and ethnicity are based on their self-identification with one or more groups.
Specifically, the race categories include White, Black or African American, American Indian or Alaska Native, Asian, Native Hawaiian or Other Pacific Islander, Other race, and Two or more races [@url:https://factfinder.census.gov/help/en/race.htm], and ethnicity categories include Hispanic/Latino or Not Hispanic/Latino [@url:https://web.archive.org/web/20010405061504/http://www.census.gov/Press-Release/www/2001/raceqandas.html].
wru uses similar race/ethnicity categories but groups American Indian or Alaska Native and Native Hawaiian or Other Pacific Islander to form the Other category.

We used only the surname of author or honoree to make predictions via the *predict_race()* function from wru.
However, in the case of names that were not observed in the census, the function outputs the average demographic distribution from the census, which may produce misleading results.
To avoid this suboptimal imputation, we modified the function to return a status denoting that results were inconclusive (NA) instead.
This prediction represents the probability of an honoree or author selecting a certain race or ethnicity on a census form if they lived within the US.

Of 239 US-affiliated ISCB honoree entries, wru fails to provide race/ethnicity predictions for 45 names.
Of 11,545 US-affiliated corresponding authors, 2,352 had a last name for which wru did not provide predictions.
One limitation of wru and other methods that infer race, ethnicity, or nationality from last names is the potentially inaccurate prediction for scientists who changed their last name during marriage, a practice more common among women than men.


## Results

### Curated Honorees and Literature-derived Potential Honorees

We curated a dataset of ISCB honorees that included 412 honorees who were keynote speakers at international ISCB-associated conferences (ISMB and RECOMB) as well as ISCB Fellows.
The ISCB Fellows set contained the complete set of Fellows named (2009--2019).
Keynote speakers were available for ISMB for all years from 1993--2019.
Keynote speakers for RECOMB were available for all years from 1997--2019.
We included individuals who were honored multiple times as separate entries.
For example, Christine Orengo was a keynote speaker at RECOMB 2004 and became an ISCB Fellow in 2016, and thus was counted twice in this list.

We sought to compare this dataset with a background distribution of potential speakers, which we considered to be last or senior authors of bioinformatics and computational biology manuscripts.
We used those published in [Bioinformatics](https://academic.oup.com/bioinformatics), [BMC Bioinformatics](https://bmcbioinformatics.biomedcentral.com/), and [PLOS Computational Biology](https://journals.plos.org/ploscompbiol/) as a set of bioinformatics and computational biology manuscripts.
We downloaded the metadata of manuscripts published in these journals from PubMed, which provided almost 30,000 articles for evaluation.
However, although PubMed provides author order, it does not provide corresponding author information.
To determine corresponding authors for an article, we used the PMC corresponding author information when it was available (20,696 articles) and the PubMed last author as a fallback when corresponding author information was missing (9,053 articles).

### Assessing Gender Diversity of Authors and Honorees

Although _Bioinformatics_ was established in 1998 and _BMC Bioinformatics_ in 2000, the metadata for these journal papers before 2002 only have initials for first and/or middle author names.
Therefore, without first and middle names, we do not have author gender predictions before this year.

We observed a slow increase of the proportion of predicted female authors, arriving at just over 20% in 2019 (Fig. {@fig:gender_breakdown}, left).
We observe very similar trend within each journal, but estimated female proportion has increased the most in _BMC Bioinformatics_ (see [notebook](https://greenelab.github.io/iscb-diversity/10.visualize-gender.html#sup_fig_s1)).
In recent years, ISCB Fellows and keynote speakers appear to be more evenly split between men and women compared to the population of authors published in computational biology and bioinformatics journals (Fig. {@fig:gender_breakdown}, right); however, it has not yet reached parity.
Further, taking all the years together, a Welch two-sample t-test did not reveal any statistically significant difference in the mean probability of ISCB honorees predicted to be female compared to that of authors (t~418~ = 0.753, _p_ = 0.226).
We observed an increasing trend of honorees who were women in each honor category, especially in the group of ISCB Fellows (see [notebook](https://greenelab.github.io/iscb-diversity/10.visualize-gender.html#sup_fig_s1)), which markedly increased after 2015.
Through 2019, there were a number of years when meetings or ISCB Fellow classes have a high probability of recognizing only male honorees and none that appeared to have exclusively female honorees.


![ISCB Fellows and keynote speakers appear more evenly split between men and women than PubMed authors in recent years, but the proportion has not reached parity. Estimated composition of gender prediction over the years of
  all Pubmed computational biology and bioinformatics journal authors (left),
  and all ISCB Fellows and keynote speakers (right)
  was computed as the average of prediction probabilities of Pubmed articles or ISCB honorees each year.
](https://raw.githubusercontent.com/greenelab/iscb-diversity/f43f7c40371343a4d8b91438b05c021fdb88af32/figs/gender_breakdown.png){#fig:gender_breakdown width="70%"}

### Predicting Name Origin Groups with LSTM Neural Networks and Wikipedia

Table @tbl:example_names shows the size of the training set for each of the name origin groups as well as a few examples of PubMed author names that had at least 90% prediction probability in that group.
We refer to this dataset as Wiki2019 (available online in [`annotated_names.tsv`](https://github.com/greenelab/wiki-nationality-estimate/blob/master/data/annotated_names.tsv)).

| Group | Training Size | Example Names |
| ------ | ------ | -------------------- |
| Celtic/English names | 154,890 | Adam O Hebb, Oliver G Pybus, David W Ritchie, James WJ Anderson, James W MacDonald, Robert Clarke |
| European names | 78,157 | Tracey M Filzen, Jos H Beijnen, Caroline Louis-Jeune, Christian Lorenzi, Boris Vassilev, Verena Heinrich |
| Hispanic names | 66,931 | Ramón Latorre, Antonio J Jimeno-Yepes, Felipe A Simão, Paulo S L de Oliveira, Juan Carlos Rodríguez-Manzaneque, Natalia Acevedo-Luna |
| East Asian names | 54,588 | Heejoon Chae, Wenchao Jiang, Haizhou Liu, Miho Uchida, Wenxuan Zhang, Jiali Feng |
| Arabic names | 31,418 | Hamidreza Chitsaz, Farzad Sangi, Habib Motieghader, Berke Ç Toptas, Ali Aliyari, Bülent Arman Aksoy |
| Nordic names | 28,978 | Cecilia M Lindgren, Ellen Larsen, Jesper R Gådin, Janne H Korhonen, Johan Åqvist, Jens Nilsson |
| South Asian names | 20,025 | Amitabh Chak, Matthew G Seetin, Matrika Gupta, Sumudu P Leelananda, VS Kumar Kolli, Swanand Gore |
| African names | 17,826 | Timothy Kinyanjui, Jammbe Z Musoro, Nyaradzo M Mgodi, Magambo Phillip Kimuda, Probhonjon Baruah, Adaoha E C Ihekwaba |
| Hebrew names | 4,549 | Alexander J Sadovsky, Boris Shraiman, Gil Goldshlager, Eytan Adar, Aviva Peleg, Nir Esterman |
| Greek names | 4,138 | Gianni Panagiotou, Themis Lazaridis, Eleni Mijalis, Nikolaos Tsiantis, Konstantinos A Kyritsis, Dimitris E Messinis |

Table: **Predicting name-origin groups of names trained on Wikipedia's living people.**
The table lists the 10 groups and the number of living people for each region that the LSTM was trained on.
Example names shows actual author names that received a high prediction for each region.
Full information about which countries comprised each region can be found in the online dataset [`country_to_region.tsv`](https://github.com/greenelab/iscb-diversity/blob/make-letters/data/countries/2020-01-31_groupings.tsv).
{#tbl:example_names}

We next aimed to predict the name origin groups of honorees and authors.
We constructed a training dataset with more than 700,000 name-nationality pairs by parsing the English-language Wikipedia.
We trained a LSTM neural network on n-grams to predict name groups.
We found similar performance across 1, 2, and 3-grams;
however, because the classifier required fewer epochs to train with 3-grams, we used this length in the model that we term Wiki2019-LSTM.
Our Wiki2019-LSTM returns, for each given name, a probability of that name originating from each of the specified 10 groups.
We observed a multiclass area under the receiver operating characteristic curve (AUC) score of 95.9% for the classifier, indicating that the classifier can recapitulate name origins with high sensitivity and specificity.
For each individual group, the high AUC (above 92%, Fig. {@fig:wiki2019_lstm}A) suggests that our classifier was sufficient for use in a broad-scale examination of disparities.
We also observed that the model was well calibrated (Fig. {@fig:wiki2019_lstm}B).
We also examined potential systematic errors between pairs of name origin groupings with a confusion heatmap and did not find off-diagonal enrichment for any pairing (Fig. {@fig:wiki2019_lstm}C).

![The Wiki2019-LSTM model performs well on the testing dataset.
The area under the ROC curve is above 92% for each category, showing strong performance across origin categories (A).
A calibration curve, computed with the caret R package, shows consistency between the predicted probabilities (midpoints of each fixed-width bin) and the observed fraction of names in each bin (B).
Heatmap showing whether names from a given group (x-axis) received higher (purple) or lower (green) predictions for each group (y-axis) than would be expected by group prevalence alone (C).
The values represent log~2~ fold change between the average predicted probability and the prevalence of the corresponding predicted group in the testing dataset (null).
Scaling by group prevalence accounts for the imbalance of groups in the testing dataset.
In all cases, the classifier predicts the true groups above the expected null probability (matrix diagonals are all purple).
For off-diagonal cells, darker green indicates a lower mean prediction compared to the null.
For example, the classifier does not often mistake East Asian names as Greek, but is more prone to mistaking South Asian names as Celtic/English.
](https://raw.githubusercontent.com/greenelab/iscb-diversity/f43f7c40371343a4d8b91438b05c021fdb88af32/figs/fig_3.png){#fig:wiki2019_lstm width=100%}

### Assessing the Name Origin Diversity of Authors and Honorees

We applied our Wiki2019-LSTM model to both our computational biology honorees dataset and our dataset of corresponding authors.
We found that the proportion of authors with Celtic/English names had decreased (Fig. {@fig:region_breakdown}A, left), particularly for papers published in _Bioinformatics_ and _BMC Bioinformatics_ (see [notebook](https://greenelab.github.io/iscb-diversity/11.visualize-name-origins.html#sup_fig_s4)).
Among keynote speakers and fellows, we found that the majority of honorees are predicted to have Celtic/English or European names (Fig. {@fig:region_breakdown}A, right).
When we directly compared honoree composition with PubMed, we observed discrepancies between the two groups, namely a large overrepresentation of keynote speakers with Celtic/English names (t~418~ = 9.01, _p_ < 10^-16^) and a substantial underrepresentation of keynote speakers with East Asian names (t~454~ = -15.8, _p_ < 10^-16^) (Fig. {@fig:region_breakdown}B).
No statistically significant difference was observed between the proportion of honorees and authors with European names (t~425~ = 0.0282, _p_ = 0.489) or in other categories (see Table @tbl:example_names, t~425~ = -0.176, _p_ = 0.860).


![Compared to the name collection of Pubmed authors, honorees with Celtic/English names are overrepresented while honorees with East Asian names are underrepresented. 
No statistically significant difference was observed between the proportion of honorees and authors with European names or in other categories (see Table @tbl:example_names).
Estimated composition of name origin prediction over the years of
  (A, left) all Pubmed computational biology and bioinformatics journal authors,
  and (A, right) all ISCB Fellows and keynote speakers
  was computed as the average of prediction probabilities of Pubmed articles or ISCB honorees each year.
  (B) For each region, the mean predicted probability of Pubmed articles is shown as teal LOESS curve, and the mean probability and 95% confidence interval of the ISCB honoree predictions are shown as dark circles and vertical lines.

](https://raw.githubusercontent.com/greenelab/iscb-diversity/f43f7c40371343a4d8b91438b05c021fdb88af32/figs/region_breakdown.png){#fig:region_breakdown}

### Affiliation Analysis

We analyzed the countries of affiliation between corresponding authors and ISCB honorees.
For each country, we report a value of log~2~ enrichment (LOE) and its 95% confidence intervals (Table @tbl:country-enrichment).
A positive value of LOE indicates a higher proportion of honorees affiliated with that country compared to authors.
A LOE value of 1 represents a one-fold enrichment (i.e., observed number of honorees is twice as much as expected).
In the 20 countries with the most publications, we found an overrepresentation of honorees affiliated with institutions and companies in the US (97 speakers more than expected, LOE = 0.6, 95% CI (0.5, 0.8)) and Israel (12 speakers more than expected, LOR = 1.6, 95% CI (0.9, 2.3)), and an underrepresentation of honorees affiliated with those in China, France, Italy, the Netherlands, Taiwan, and India (Fig. @fig:country-enrichment).

![The overrepresentation of honorees affiliated with institutions and companies in the US and Israel contrasts the underrepresentation of honorees affiliated with those in China, France, Italy, the Netherlands, Taiwan, and India.
Each country's log~2~ enrichment (LOE) and its 95% confidence interval are displayed on the left.
Observed (triangle) and expected (circle) number of honorees and their differences (observed - expected) are shown in square-root scale on the right.
Countries are ordered based on the proportion of authors in the field.

](https://raw.githubusercontent.com/greenelab/iscb-diversity/a61b73ed80ba2062d31a1f111c1b8f388fda4b3a/figs/enrichment-plot.png){#fig:country-enrichment width="80%"}

| Country        | Author proportion | Observed | Expected | Observed - Expected | Enrichment | Log~2~(Enrichment) | 95% Confidence Interval |
|----------------|-------------------|----------|----------|---------------------|------------|------------------|-------------------------|
| United States  | 38.76%            | 237.5    | 152.7    | 84.8                | 1.6        | 0.6              | (0.4, 0.8)              |
| United Kingdom | 8.36%             | 36.0     | 32.9     | 3.1                 | 1.1        | 0.1              | (-0.4, 0.6)             |
| Germany        | 7.55%             | 27.0     | 29.7     | -2.7                | 0.9        | -0.1             | (-0.7, 0.4)             |
| China          | 5.82%             | 3.0      | 22.9     | -19.9               | 0.1        | -2.9             | (-5.2, -1.4)            |
| France         | 3.86%             | 4.0      | 15.2     | -11.2               | 0.3        | -1.9             | (-3.8, -0.6)            |
| Italy          | 3.04%             | 2.0      | 12.0     | -10.0               | 0.2        | -2.6             | (-5.6, -0.7)            |
| Canada         | 3.03%             | 12.0     | 11.9     | 0.1                 | 1.0        | 0.0              | (-1, 0.8)               |
| Japan          | 2.44%             | 9.0      | 9.6      | -0.6                | 0.9        | -0.1             | (-1.2, 0.8)             |
| Spain          | 2.39%             | 6.0      | 9.4      | -3.4                | 0.6        | -0.7             | (-2.1, 0.5)             |
| Australia      | 2.33%             | 5.0      | 9.2      | -4.2                | 0.5        | -0.9             | (-2.5, 0.4)             |
| Netherlands    | 1.91%             | 1.0      | 7.5      | -6.5                | 0.1        | -2.9             | (-8.2, -0.4)            |
| Switzerland    | 1.81%             | 7.0      | 7.1      | -0.1                | 1.0        | -0.0             | (-1.4, 1)               |
| Israel         | 1.46%             | 17.5     | 5.8      | 11.7                | 3.0        | 1.6              | (0.8, 2.3)              |
| Sweden         | 1.34%             | 6.0      | 5.3      | 0.7                 | 1.1        | 0.2              | (-1.3, 1.3)             |
| Korea          | 1.30%             | 1.0      | 5.1      | -4.1                | 0.2        | -2.4             | (-7.7, 0.1)             |
| Taiwan         | 1.25%             | 0.0      | 4.9      | -4.9                | 0.0        | -Inf             | (-Inf, -0.4)            |
| India          | 1.20%             | 0.0      | 4.7      | -4.7                | 0.0        | -Inf             | (-Inf, -0.3)            |
| Belgium        | 1.04%             | 1.0      | 4.1      | -3.1                | 0.2        | -2.0             | (-7.3, 0.5)             |
| Singapore      | 0.88%             | 1.0      | 3.5      | -2.5                | 0.3        | -1.8             | (-7.1, 0.7)             |
| Finland        | 0.85%             | 0.0      | 3.4      | -3.4                | 0.0        | -Inf             | (-Inf, 0.1)             |

Table: **Enrichment and depletion in proportion of ISCB honorees compared to Pubmed corresponding authors of 20 countries with the most publications.**
The table lists the countries and their corresponding enrichment, which we computed by dividing the observed proportion of honorees by expected proportion of honorees.
The expected proportion was calculated using corresponding author proportions.
A positive Log~2~(Enrichment) indicated a higher proportion of honorees than corresponding authors affiliated with that country.
The full table with all countries can be browsed interactively in the corresponding [analysis notebook](https://greenelab.github.io/iscb-diversity/12.analyze-affiliation.html#enrichment_tab).
{#tbl:country-enrichment}


### Assessing the Racial and Ethnic Diversity of US-affiliated Authors and Honorees

We predicted the race and ethnicity of US-affiliated authors and honorees using wru, which is based on US census data.
We found that an increasing proportion of authors in computational biology and bioinformatics journals had last names associated with selecting Asian as a race/ethnicity category in the US census (Fig. {@fig:us_racial_makeup}A).
This was primarily driven by publications in _Bioinformatics_ and _BMC Bioinformatics_ (Fig. {@fig:us_racial_makeup}B, top).
We did not observe a corresponding increase at _PLOS Computational Biology_ (Fig. {@fig:us_racial_makeup}B, bottom).
Compared to Pubmed authors, ISCB honorees with US affiliations have a higher proportion of individuals whose last names we associated with selecting white as a race/ethnicity category in the US census (Fig. {@fig:us_racial_makeup}C vs. A).
Separating honoree results by honor category did not reveal any clear differences (Fig. {@fig:us_racial_makeup}D).

![We find an overrepresentation of white and underrepresentation of Asian honorees as compared to authors. Estimated composition of census-based race/ethnicity prediction over the years of
  (A) all Pubmed computational biology and bioinformatics journal authors,
  (B) authors in each journal,
  (C) all ISCB Fellows and keynote speakers,
  and (D) ISCB honorees in each honor category
  was computed as the average of prediction probabilities of Pubmed articles or ISCB honorees each year.
  For each race/ethnicity category, the mean predicted probability of Pubmed articles is shown as teal LOESS curve, and the mean probability and 95% confidence interval of the ISCB honoree predictions are shown as dark circles and vertical lines (E).

](https://raw.githubusercontent.com/greenelab/iscb-diversity/f43f7c40371343a4d8b91438b05c021fdb88af32/figs/us_racial_makeup.png){#fig:us_racial_makeup}

We directly compared honoree and author results from 1993 to 2019 for the predicted proportion of white, Asian, and other categories (Fig. {@fig:us_racial_makeup}E).
We found that, over the years, white honorees have been significantly overrepresented (t~218~ = 14.8, _p_ < 10^-16^) and Asian honorees have been significantly underrepresented (t~236~ = -18.8, _p_ < 10^-16^).
A Welch two-sample t-test did not reveal any statistically significant difference in the mean probability of ISCB speakers predicted to be in Other categories compared to authors (t~203~ = 1.79, _p_ = 0.0747).

### Assessing the Name Origin Diversity of US-affiliated Authors and Honorees

We applied our Wiki2019-LSTM model to US-affiliated authors and honorees and found similar pattern as when we considered all authors and honorees.
We note that the US was not included in the training of the Wiki2019-LSTM model (see Methods).
Specifically, the proportion of authors with Celtic/English names had decreased (Fig. {@fig:us_name_origin}A, left), particularly for papers published in _Bioinformatics_ and _BMC Bioinformatics_ (see [notebook](https://greenelab.github.io/iscb-diversity/14.us-name-origin.html#sup_fig_s6)).
Meanwhile, the majority of honorees are predicted to have Celtic/English or European names (Fig. {@fig:us_name_origin}A, right).
When we directly compared honoree composition with PubMed, we observed discrepancies between the two groups, namely a large overrepresentation of honorees with Celtic/English names (t~247~ = 6.46, _p_ < 10^-9^), a smaller overrepresentation of honorees with European names (t~250~ = 2.54, _p_ = 0.0059), and a substantial underrepresentation of honorees with East Asian names (t~329~ = -20.6, _p_ < 10^-16^) (Fig. {@fig:us_name_origin}B).


![Compared to the name collection of US-affiliated Pubmed authors, US-affiliated honorees with Celtic/English and European names are overrepresented while US-affiliated honorees with East Asian names are underrepresented.
No statistically significant difference was observed between the proportion of honorees and authors with names in other categories (see Table @tbl:example_names, t~252~ = -0.152, _p_ = 0.879).
Estimated composition of name origin prediction over the years of
  (A, left) US-affiliated journal authors,
  and (A, right) all US-affiliated Fellows and keynote speakers
  was computed as the average of prediction probabilities of US-affiliated corresponding authors or ISCB honorees each year.
  (B) For each region, the mean predicted probability of US-affiliated corresponding authors is shown as teal LOESS curve, and the mean probability and 95% confidence interval of the US-affiliated ISCB honoree predictions are shown as dark circles and vertical lines.

](https://raw.githubusercontent.com/greenelab/iscb-diversity/f43f7c40371343a4d8b91438b05c021fdb88af32/figs/us_name_origin.png){#fig:us_name_origin}


## Conclusions

A major challenge that we faced in carrying out this work was to narrow down geographic origins for some groups of names.
Some name origin groups, such as Hispanic names, are geographically disparate.
We were unable to construct a classifier that could distinguish between names from Iberian countries (Spain and Portugal) from those in Latin America in the group of Hispanic names.
Discrepancies in representation between these groups are thus undetectable by our classifier.
Honoree counts of those with Hispanic names are influenced from Spain as well as Latin America.
In such cases, our analyses may substantially understate the extent to which minoritized scientists are underrepresented among honorees and authors.

Biases in authorship practices may also result in our underestimation of the composition of minoritized scientists within the field.
We estimated the composition of the field using corresponding author status, but in neuroscience [@doi:10.1101/275362] and other disciplines [@doi:10.1371/journal.pbio.2004956] women are underrepresented among such authors.
Such an effect would cause us to underestimate the number of women in the field.
Though this effect has been studied with respect to gender, we are not aware of similar work examining race, ethnicity, or name origins.

We acknowledged that our supervised learning approaches are neither error free nor bias free.
Because wru was trained on the US census to make predictions, many of the missing predictions are on names not observed in the US census.
Although the underestimation of the proportion of these names could not be quantified in the list of authors and honorees, we complemented this race/ethnicity prediction method with an additional name origin analysis.
By integrating different methods and preserving uncertainty by analyzing prediction probabilities rather than applying a hard assignment for each prediction, we hope to alleviate these biases and discover insightful findings that correctly reflect the current representation diversity at conferences.

Focusing on an international society and meetings, we measured honor and authorship rates worldwide.
In this setting, we observe disparities by name groups.
Because invitation and honor patterns could be driven by biases associated with name groups, geography, or other factors, we cross-referenced name group predictions with author affiliations to disentangle the relationship between geographic regions, name groups and invitation probabilities.
We found that disparities persisted even within the group of honorees with a US affiliation.

An important questions to ask when measuring representation is what the right level of representation is.
We suggest that considering equity may be more appropriate than strictly diversity.
For example, we found similar representation of women between authors and honorees, which suggests honoree diversity is similar to that of authors.
However, if fewer women are in the field because of systemic factors that inhibit their participation, we would not have reached equity.
In addition to holding fewer corresponding authorship positions, on average, female scientists of different disciplines are cited less often [@arxiv:2001.01002, @doi:10.1002/ece3.4993], invited by journals to submit papers less often [@doi:10.1371/journal.pbio.2004956], suggested as reviewers less often [@doi:10.1038/541455a], and receive significantly worse review scores [@doi:10.1002/ece3.4993].
Societies, both through their honorees and the individuals who deliver keynotes at their meetings, can play a positive role in improving the presence of female STEM role models, which, for example, may lead to higher persistence for undergraduate women in geoscience [@doi:10.1130/GES01659.1].
Efforts are underway to create Wikipedia entries for more female [@doi:10.1038/d41586-018-05947-8] and black, Asian, and minority scientists [@doi:10.1038/d41586-019-00812-8], which can help early-career scientists identify role models.
We find that ISCB's honorees and keynote speakers, though not yet reaching gender parity, appear to have similar gender proportion to the field as a whole.
On the other hand, honorees include significantly fewer people of color than the field as a whole, and Asian scientists are dramatically underrepresented among honorees.
Although we estimate the fraction of non-white and non-Asian authors to be relatively similar to the estimated honoree rate, we note that both are represented at levels substantially lower than in the US population.
Societies can play a positive role in enhancing equity if they design policies to honor scientists in ways that counter these biases.

The central role that scientists play in evaluating each other and each other's findings makes equity critical.
Even many nominally objective methods of assessing excellence (e.g., h-index, grant funding obtained, number of high-impact peer-reviewed publications, and total number of peer-reviewed publications) are subject to the bias of peers during review.
These could be affected by explicit biases, implicit biases, or pernicious biases in which a reviewer might consider a path of inquiry, as opposed to an individual, to be more or less meritorious based on the reviewer's own background [@doi:10.1126/sciadv.aaw7238].
Our efforts to measure the diversity of honorees in an international society suggests that, while a focus on gender parity may be improving some aspects of diversity among honorees, contributions from scientists of color are underrecognized.


## Data and Resource Availability

This manuscript was written [openly on GitHub](https://github.com/greenelab/iscb-diversity-manuscript) using Manubot [@doi:10.1371/journal.pcbi.1007128].
The Manubot HTML version is available under a Creative Commons Attribution (CC BY 4.0) License at <https://greenelab.github.io/iscb-diversity-manuscript/>.
Our analysis of authors and ISCB-associated honorees is available under CC BY 4.0 at <https://github.com/greenelab/iscb-diversity>, with source code also distributed under a BSD 3-Clause License.
Rendered Python and R notebooks from this repository are browsable at <https://greenelab.github.io/iscb-diversity/>.
Our analysis of PubMed, PubMed Central, and author names relies on the Python pubmedpy package, developed as part of this project and available under a Blue Oak Model License 1.0 at <https://github.com/dhimmel/pubmedpy> and on [PyPI](https://pypi.org/project/pubmedpy/).
Our Wikipedia name dataset is dedicated to the public domain under CC0 License at <https://github.com/greenelab/wiki-nationality-estimate>, with source code to construct the dataset available under a BSD 3-Clause License.


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
